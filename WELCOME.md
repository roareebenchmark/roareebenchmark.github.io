---
layout: default
title: Get Started
nav_order: 2
---

# Welcome to Roaree Benchmark ü¶Å

Roaree Benchmark is a student-led research group at Columbia University dedicated to the rigorous evaluation of Large Language Models and AI platforms. 

### üöÄ Join the Project Team
Your first step to getting involved is to register via our official intake form. This helps us track interests and assign research tracks.
**[SIGN UP HERE](https://forms.gle/MZpzXQ2hXNEMD18o7)**

---

### Our Mission
We provide transparency in the AI ecosystem by "grading" the latest LLM models. We move beyond standard benchmarks to test for reasoning, reliability, and real-world utility within academic and professional environments.

### Why Get Involved?

**For Students**
* **Active Research:** Gain hands-on experience in AI/ML evaluation and open-source collaboration.
* **Community:** Join a network of Columbia students passionate about the future of AI.
* **Skill Building:** Master the tools used to test and deploy state-of-the-art models.

**For Faculty & Alumni**
* **Collaboration:** Engage with a motivated cohort of researchers to stay ahead of the LLM curve.
* **Insights:** Access fresh, data-driven benchmarks that highlight the strengths and weaknesses of new AI releases.

---
*Roar, Lions, Roar!*

---

**Questions about this guide?** Open a discussion or ask in team channels.

**Ready to contribute?** Check out [CONTRIBUTING.md](CONTRIBUTING.md) for next steps!

*Roar, Lions, Roar! ü¶Å*
